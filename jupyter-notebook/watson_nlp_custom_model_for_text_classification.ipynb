{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Import the requests library\n",
    "import pathlib\n",
    "import zipfile\n",
    "import wget\n",
    "import os\n",
    "import requests\n",
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install wget\n",
    "!pip install os\n",
    "!pip install zipfile\n",
    "!pip install pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Set the path for the download: Usage of Consumer complaint database to walk you through the process. (https://www.consumerfinance.gov/data-research/consumer-complaints/)\n",
    "URL = \"https://files.consumerfinance.gov/ccdb/complaints.csv.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. download the data behind the URL\n",
    "response = requests.get(URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Open the response into a new file called complaints.csv.zip\n",
    "open(\"complaints.csv.zip\", \"wb\").write(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 5. Verify the path and list the existing variables types, and files\n",
    "directory = os.getcwd()\n",
    "arr = os.listdir(directory)\n",
    "print(\"The variable, arr is of type:\", type(arr))\n",
    "print(\"The variable, directory is of type:\", type(directory))\n",
    "print(\"Directory '% s' created\" % directory)\n",
    "print(\"List '% s' created\" % arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Unzip the downloaded file and verify that the file was unzipped\n",
    "filepath = directory + \"/complaints.csv.zip\"\n",
    "with zipfile.ZipFile(filepath, 'r') as zip_ref:\n",
    "    zip_ref.extractall(directory)\n",
    "arr = os.listdir(directory)\n",
    "csv_files = list(pathlib.Path(directory).glob('*.csv'))\n",
    "\n",
    "print(\"Directory '% s' created\" % directory)\n",
    "print(\"List '% s' created\" % arr)\n",
    "print(\"Csv files '% s' created\" % csv_files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Reduce model training time and quick analysis using \"frac\". (https://en.wikipedia.org/wiki/Fractional_part)\n",
    "filepath = directory + \"/complaints.csv\"\n",
    "complaint_df = pandas.read_csv(filepath, error_bad_lines=False)\n",
    "complaint_df = complaint_df.sample(frac=0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Look at all of the product groups that are available in the data set because these are the classes that the classifier should predict from a given complaint text.\n",
    "complaint_df['Product'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. Filter on the Product categories with a relevant number of samples and remove any other product category from further analysis because many classification algorithms work best if the training samples are equally split across the classes. If the data is unbalanced, algorithms might decide to favor classes with many samples to achieve an overall good result.\n",
    "train_test_df = complaint_df[(complaint_df['Product'] == 'Credit reporting, credit repair services, or other personal consumer reports') | \\\n",
    "                             (complaint_df['Product'] == 'Debt collection') | \\\n",
    "                             (complaint_df['Product'] == 'Mortgage') | \\\n",
    "                             (complaint_df['Product'] == 'Credit card or prepaid card') | \\\n",
    "                             (complaint_df['Product'] == 'Checking or savings account')\n",
    "                            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. List the first 5 test entries for the training\n",
    "train_test_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11. Split the data into training and test data (ratio: 80/20).\n",
    "# 80% training data\n",
    "train_orig_df = train_test_df.groupby('Product').sample(frac=0.8, random_state=6)\n",
    "print(\"Training data:\")\n",
    "print(\"Number of training samples: {}\".format(len(train_orig_df)))\n",
    "print(\"Samples by product group:\\n{}\".format(train_orig_df['Product'].value_counts()))\n",
    "\n",
    "# 20% test data\n",
    "test_orig_df = train_test_df.drop(train_orig_df.index)\n",
    "print(\"\\nTest data:\")\n",
    "print(\"Number of test samples: {}\".format(len(test_orig_df)))\n",
    "print(\"Samples by product group:\\n{}\".format(test_orig_df['Product'].value_counts()))\n",
    "\n",
    "# re-index after sampling\n",
    "train_orig_df = train_orig_df.reset_index(drop=True)\n",
    "test_orig_df = test_orig_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12. Create the data in a JSON format. The training and test data is written to files. \n",
    "def prepare_data(df):\n",
    "       # only the text column and the target label *Product* are needed\n",
    "       df_out = df[['Consumer complaint narrative', 'Product']].reset_index (drop=True)\n",
    "       # rename to the identifiers expected by Watson NLP\n",
    "       df_out = df_out.rename(columns={\"Consumer complaint narrative\": \"text\", 'Product': 'labels'})\n",
    "       # the label column should be an array (although we have only one label per complaint)\n",
    "       df_out['labels'] = df_out['labels'].map(lambda label: [label,])\n",
    "       return df_out\n",
    "\n",
    "train_df = prepare_data(train_orig_df)\n",
    "train_file = './train_data.json'\n",
    "train_df.to_json(train_file, orient='records')\n",
    "\n",
    "test_df = prepare_data(test_orig_df)\n",
    "test_file = './test data.json'\n",
    "test_df.to_json(test_file, orient='records')\n",
    "\n",
    "json_files = list(pathlib.Path(directory).glob('*.json'))\n",
    "print(\"JSON files '% s' created\" % json_files)\n",
    "\n",
    "train_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 13. Show labels\n",
    "test_df.explode('labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
